import matplotlib  # Matplotlib ä¸»åº“ï¼Œç”¨äºç»˜å›¾ä¸åç«¯è®¾ç½®
import torch  # PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶
import numpy as np  # NumPyï¼Œç”¨äºæ•°å€¼è®¡ç®—ä¸æ•°ç»„æ“ä½œ
import matplotlib.pyplot as plt  # Matplotlib ç»˜å›¾æ¥å£
from datetime import datetime  # ç”¨äºç”Ÿæˆæ—¶é—´æˆ³
import time  # ç”¨äºè®¡æ—¶
import os  # ç”¨äºæ–‡ä»¶ä¸ç›®å½•æ“ä½œ

# ============================
# Matplotlib ä¸­æ–‡è®¾ç½®
# ============================
matplotlib.use("TkAgg")  # æŒ‡å®š Matplotlib ä½¿ç”¨ TkAgg åç«¯
matplotlib.rcParams['font.family'] = 'sans-serif'  # è®¾ç½®å­—ä½“æ—ä¸ºæ— è¡¬çº¿å­—ä½“
matplotlib.rcParams['font.sans-serif'] = [  # æŒ‡å®šå¯ç”¨çš„ä¸­æ–‡å­—ä½“åˆ—è¡¨
    'SimHei', 'Noto Sans CJK SC', 'WenQuanYi Micro Hei'
]
matplotlib.rcParams['axes.unicode_minus'] = False  # è§£å†³åæ ‡è½´è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜

# ============================
# 1. è®¾å¤‡é€‰æ‹©
# ============================
use_cuda = torch.cuda.is_available()  # åˆ¤æ–­å½“å‰ç¯å¢ƒæ˜¯å¦æ”¯æŒ CUDA
device = torch.device("cuda" if use_cuda else "cpu")  # æ ¹æ®æ˜¯å¦æ”¯æŒ CUDA é€‰æ‹©è®¡ç®—è®¾å¤‡

print("=" * 80)  # è¾“å‡ºåˆ†éš”çº¿
print("è®¡ç®—è®¾å¤‡ä¿¡æ¯")  # è¾“å‡ºæç¤ºä¿¡æ¯
print(f"æ˜¯å¦æ”¯æŒ CUDA: {use_cuda}")  # è¾“å‡º CUDA æ”¯æŒæƒ…å†µ
print(f"å½“å‰è®¡ç®—è®¾å¤‡: {device}")  # è¾“å‡ºå½“å‰ä½¿ç”¨çš„è®¡ç®—è®¾å¤‡
print("=" * 80)  # è¾“å‡ºåˆ†éš”çº¿

# ============================
# 2. è¾“å‡ºç›®å½•
# ============================
out_dir = "figures"  # è®¾ç½®å›¾åƒè¾“å‡ºç›®å½•
os.makedirs(out_dir, exist_ok=True)  # è‹¥ç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»º
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")  # ç”Ÿæˆå½“å‰æ—¶é—´æˆ³å­—ç¬¦ä¸²

# ============================
# 3. æ„é€ äºŒç»´éçº¿æ€§æ•°æ®
# ============================
torch.manual_seed(42)  # å›ºå®šéšæœºç§å­ï¼Œä¿è¯å®éªŒå¯å¤ç°

n = 200  # è®¾ç½®æ ·æœ¬æ•°é‡ï¼ˆæ ·æœ¬é‡è¾ƒå¤§ï¼Œç»“æœæ›´ç¨³å®šï¼‰
X = torch.linspace(0, 2 * torch.pi, n, device=device)  # åœ¨ [0, 2Ï€] åŒºé—´ç”Ÿæˆå‡åŒ€é‡‡æ ·ç‚¹
noise = torch.randn(n, device=device) * 0.2  # ç”Ÿæˆé«˜æ–¯å™ªå£°
y = torch.sin(X) + noise  # æ„é€ çœŸå®æ•°æ® y = sin(x) + Îµ

print("çœŸå®æ•°æ®è§„å¾‹ï¼šy = sin(x) + Îµ")  # è¾“å‡ºçœŸå®æ•°æ®ç”Ÿæˆè§„å¾‹
print(f"æ ·æœ¬æ•°é‡: {n}")  # è¾“å‡ºæ ·æœ¬æ•°é‡

X_np = X.detach().cpu().numpy()  # å°† X ä» GPU å¼ é‡è½¬ä¸º NumPy æ•°ç»„
y_np = y.detach().cpu().numpy()  # å°† y ä» GPU å¼ é‡è½¬ä¸º NumPy æ•°ç»„

# ============================
# 4. ğŸ”¥ å…ˆæ‰«ææŸå¤±æ›²é¢ï¼Œå¯»æ‰¾â€œå±±é¡¶â€
# å›ºå®š w2ï¼Œåªåœ¨ (w1, b) å¹³é¢ä¸Šè§‚å¯Ÿ
# ============================
w2_fixed = 0.0  # å›ºå®šå‚æ•° w2 çš„å–å€¼

w1_range = np.linspace(-6, 6, 200)  # è®¾ç½® w1 çš„æœç´¢èŒƒå›´
b_range  = np.linspace(-6, 6, 200)  # è®¾ç½® b çš„æœç´¢èŒƒå›´
W1, B = np.meshgrid(w1_range, b_range)  # æ„é€ å‚æ•°ç½‘æ ¼

Loss_surface = np.zeros_like(W1)  # åˆå§‹åŒ–æŸå¤±æ›²é¢çŸ©é˜µ

for i in range(W1.shape[0]):  # éå† w1 ç½‘æ ¼
    for j in range(W1.shape[1]):  # éå† b ç½‘æ ¼
        y_hat = (  # è®¡ç®—å½“å‰å‚æ•°ä¸‹çš„é¢„æµ‹å€¼
            W1[i, j] * np.sin(X_np)  # w1 * sin(x)
            + w2_fixed * np.cos(X_np)  # w2 * cos(x)
            + B[i, j]  # åç½®é¡¹ b
        )
        Loss_surface[i, j] = np.mean((y_hat - y_np) ** 2)  # è®¡ç®—å‡æ–¹è¯¯å·®æŸå¤±

max_idx = np.unravel_index(np.argmax(Loss_surface), Loss_surface.shape)  # æ‰¾åˆ°æŸå¤±æœ€å¤§çš„ç´¢å¼•
w1_top = W1[max_idx]  # å¯¹åº”çš„ w1 å€¼
b_top  = B[max_idx]  # å¯¹åº”çš„ b å€¼
max_loss = Loss_surface[max_idx]  # æœ€å¤§æŸå¤±å€¼

print("ğŸ¯ æ‰¾åˆ°æŸå¤±æ›²é¢é¡¶ç‚¹ï¼ˆå±±é¡¶ï¼‰ï¼š")  # è¾“å‡ºæç¤ºä¿¡æ¯
print(f"w1_top = {w1_top:.3f}, b_top = {b_top:.3f}, Loss = {max_loss:.3f}")  # è¾“å‡ºå±±é¡¶å‚æ•°

# ============================
# 5. ä»â€œå±±é¡¶â€åˆå§‹åŒ–æ¨¡å‹å‚æ•°
# ============================
w1 = torch.tensor([w1_top], device=device, requires_grad=True)  # åˆå§‹åŒ– w1ï¼Œå¹¶å¼€å¯æ¢¯åº¦
w2 = torch.tensor([w2_fixed], device=device, requires_grad=True)  # åˆå§‹åŒ– w2ï¼Œå¹¶å¼€å¯æ¢¯åº¦
b  = torch.tensor([b_top], device=device, requires_grad=True)  # åˆå§‹åŒ– bï¼Œå¹¶å¼€å¯æ¢¯åº¦

lr = 0.01  # è®¾ç½®å­¦ä¹ ç‡
epochs = 300  # è®¾ç½®è®­ç»ƒè½®æ•°

loss_history = []  # ç”¨äºè®°å½•æ¯ä¸€è½®çš„æŸå¤±å€¼
param_history = []  # ç”¨äºè®°å½•å‚æ•°è½¨è¿¹ (w1, b, loss)

# ============================
# 6. å…¨é‡æ¢¯åº¦ä¸‹é™è®­ç»ƒ
# ============================
print("=" * 80)  # è¾“å‡ºåˆ†éš”çº¿
print("ä»æŸå¤±æ›²é¢å±±é¡¶å¼€å§‹æ¢¯åº¦ä¸‹é™")  # è¾“å‡ºæç¤ºä¿¡æ¯
print("=" * 80)  # è¾“å‡ºåˆ†éš”çº¿

start_time = time.time()  # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´

for epoch in range(epochs):  # è®­ç»ƒå¾ªç¯
    y_pred = w1 * torch.sin(X) + w2 * torch.cos(X) + b  # å‰å‘è®¡ç®—é¢„æµ‹å€¼
    loss = torch.mean((y_pred - y) ** 2)  # è®¡ç®—å‡æ–¹è¯¯å·®æŸå¤±

    loss.backward()  # åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦

    with torch.no_grad():  # åœ¨æ— æ¢¯åº¦æ¨¡å¼ä¸‹æ›´æ–°å‚æ•°
        w1 -= lr * w1.grad  # æ›´æ–° w1
        w2 -= lr * w2.grad  # æ›´æ–° w2
        b  -= lr * b.grad  # æ›´æ–° b

    w1.grad.zero_()  # æ¸…ç©º w1 çš„æ¢¯åº¦
    w2.grad.zero_()  # æ¸…ç©º w2 çš„æ¢¯åº¦
    b.grad.zero_()  # æ¸…ç©º b çš„æ¢¯åº¦

    loss_history.append(loss.item())  # è®°å½•å½“å‰æŸå¤±
    param_history.append([w1.item(), b.item(), loss.item()])  # è®°å½•å‚æ•°è½¨è¿¹

    if (epoch + 1) % 50 == 0 or epoch == 0:  # å®šæœŸè¾“å‡ºè®­ç»ƒä¿¡æ¯
        print(
            f"ç¬¬ {epoch+1:03d} è½® | "
            f"Loss={loss.item():.6f} | "
            f"w1={w1.item():.4f}, b={b.item():.4f}"
        )

print("=" * 80)  # è¾“å‡ºåˆ†éš”çº¿
print(f"è®­ç»ƒç»“æŸï¼Œç”¨æ—¶ {time.time() - start_time:.4f} ç§’")  # è¾“å‡ºè®­ç»ƒè€—æ—¶
print("=" * 80)  # è¾“å‡ºåˆ†éš”çº¿

param_history = np.array(param_history)  # å°†å‚æ•°å†å²è½¬æ¢ä¸º NumPy æ•°ç»„

# ============================
# 7ï¸âƒ£ äºŒç»´ï¼šæ•°æ®ç©ºé—´ä¸­çš„æ‹Ÿåˆç»“æœ
# ============================
y_fit = (  # è®¡ç®—æœ€ç»ˆæ‹Ÿåˆæ›²çº¿
    w1.detach().cpu().numpy() * np.sin(X_np)
    + w2.detach().cpu().numpy() * np.cos(X_np)
    + b.detach().cpu().numpy()
)

plt.figure(figsize=(7, 5))  # åˆ›å»ºç»˜å›¾çª—å£
plt.scatter(X_np, y_np, alpha=0.6, label="æ ·æœ¬æ•°æ®")  # ç»˜åˆ¶æ•£ç‚¹å›¾
plt.plot(X_np, y_fit, color="black", linewidth=2, label="æœ€ç»ˆæ‹Ÿåˆæ›²çº¿")  # ç»˜åˆ¶æ‹Ÿåˆæ›²çº¿
plt.xlabel("è¾“å…¥ x")  # è®¾ç½® x è½´æ ‡ç­¾
plt.ylabel("è¾“å‡º y")  # è®¾ç½® y è½´æ ‡ç­¾
plt.title("äºŒç»´æ•°æ®ç©ºé—´ä¸­çš„éçº¿æ€§å›å½’æ‹Ÿåˆç»“æœ")  # è®¾ç½®æ ‡é¢˜
plt.legend()  # æ˜¾ç¤ºå›¾ä¾‹
plt.grid(True)  # æ˜¾ç¤ºç½‘æ ¼

fit_path = f"{out_dir}/fit_from_peak_{timestamp}.png"  # æ‹Ÿåˆç»“æœå›¾åƒè·¯å¾„
plt.savefig(fit_path, dpi=300)  # ä¿å­˜å›¾åƒ
plt.show()  # æ˜¾ç¤ºå›¾åƒ
plt.close()  # å…³é—­ç»˜å›¾çª—å£

# ============================
# 8ï¸âƒ£ ä¸‰ç»´ï¼šæŸå¤±æ›²é¢ + æ¢¯åº¦ä¸‹é™è½¨è¿¹
# ============================
fig = plt.figure(figsize=(9, 7))  # åˆ›å»ºä¸‰ç»´ç»˜å›¾çª—å£
ax = fig.add_subplot(111, projection="3d")  # æ·»åŠ ä¸‰ç»´åæ ‡è½´

ax.plot_surface(W1, B, Loss_surface, cmap="viridis", alpha=0.75)  # ç»˜åˆ¶æŸå¤±æ›²é¢
ax.plot(
    param_history[:, 0],  # w1 è½¨è¿¹
    param_history[:, 1],  # b è½¨è¿¹
    param_history[:, 2],  # æŸå¤±è½¨è¿¹
    color="red",
    marker="o",
    linewidth=2,
    label="æ¢¯åº¦ä¸‹é™è½¨è¿¹"
)

ax.set_xlabel("å‚æ•° w1")  # è®¾ç½® x è½´æ ‡ç­¾
ax.set_ylabel("å‚æ•° b")  # è®¾ç½® y è½´æ ‡ç­¾
ax.set_zlabel("æŸå¤±å€¼ï¼ˆMSEï¼‰")  # è®¾ç½® z è½´æ ‡ç­¾
ax.set_title("ä»æŸå¤±æ›²é¢å±±é¡¶å¼€å§‹çš„æ¢¯åº¦ä¸‹é™è½¨è¿¹")  # è®¾ç½®æ ‡é¢˜
ax.legend()  # æ˜¾ç¤ºå›¾ä¾‹

surface_path = f"{out_dir}/loss_surface_with_peak_path_{timestamp}.png"  # ä¸‰ç»´å›¾åƒè·¯å¾„
plt.savefig(surface_path, dpi=300)  # ä¿å­˜ä¸‰ç»´å›¾åƒ
plt.show()  # æ˜¾ç¤ºå›¾åƒ
plt.close()  # å…³é—­ç»˜å›¾çª—å£

print("\nå›¾åƒå·²ä¿å­˜ï¼š")  # è¾“å‡ºæç¤ºä¿¡æ¯
print(fit_path)  # è¾“å‡ºäºŒç»´æ‹Ÿåˆå›¾è·¯å¾„
print(surface_path)  # è¾“å‡ºä¸‰ç»´æŸå¤±æ›²é¢å›¾è·¯å¾„
